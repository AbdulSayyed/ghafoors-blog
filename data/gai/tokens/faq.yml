- title: What are tokens in AI APIs?
  content: |
    Tokens are crucial fragments of the ChatGPT API, representing segments of words. Before processing prompts, the API breaks down the input into these individual tokens. Tokens can include trailing spaces and sub-words, and do not necessarily align exactly with the start or end of words.

- title: What are token limits in AI APIs?
  content: |
    Requests for OpenAI's language models are constrained by a token limit shared between the prompt and completion, which depends on the `model's context window`. For example, the `text-davinci-003 model` has a 4097-token limit. If the prompt uses 4000 tokens, the completion can use a maximum of 97 tokens. Creative solutions to stay within these constraints include condensing the prompt or splitting the text into smaller chunks. Always verify the token limit specific to the model in use.

- title: Give example of different models' token limits 
  content: |
    Model-Specific Token Limits:
      - The token limit of 4097 is specific to certain models like text-davinci-003.
    Other models, such as GPT-4 or GPT-3.5, have different limits. For example:
        - GPT-4 (8k context): 8192 tokens.
        - GPT-4 (32k context): 32,768 tokens.
        - GPT-3.5-turbo: 4096 tokens.
    Dependent on Context Window:
      - The exact token limit depends on the model's context window, which varies across OpenAI's offerings.
    Exact Token Distribution:
      - The 4097-token limit includes not just the prompt and completion, but also other factors like system messages in chat-based models. This is relevant if the model adds instructions or metadata automatically.

- title: How is token pricing structured?
  content: |
    The API offers various model types at different price points. Each model has a range of capabilities, with "gpt-3.5-turbo" being the most capable. Requests made to these models have different prices, with detailed information available on the product API page.

- title: How does the API explore tokens?
  content: |
    The API treats words based on their context in the corpus data. GPT-3 converts the input into a list of tokens, processes the prompt, and converts the predicted tokens back into words as a response. Identical words may be generated as different tokens depending on their context within the text.

- title: What are popular token tools?
  content: |
    The OpenAI interactive tokenizer tool helps calculate the number of tokens and observe how text is broken down into tokens. For programmatic tokenization, Tiktoken is a fast BPE tokenizer designed for OpenAI models. Other libraries include the transformers package for Python and the gpt-3-encoder package for Node.js.

- title: How can tokens be counted for an OpenAI API call?
  content: |
    To count tokens for an OpenAI API call, follow these steps:
    - Identify the API endpoint and review the API documentation.
    - Check if token-based authentication is required and obtain an access token.
    - Count each API call with the access token in the request header as one token.
    - Track token usage to ensure staying within any usage limits or quotas set by the API provider.

- title: What are the OpenAI guidelines for token count?
  content: |
    According to OpenAI:
    - 1 token is approximately 4 characters in English.
    - 1 token is approximately 3/4 of a word.
    - 100 tokens are approximately 75 words.
    - 1-2 sentences are approximately 30 tokens.
    - 1 paragraph is approximately 100 tokens.
    - 1,500 words are approximately 2048 tokens.

- title: How can AI costs be estimated?
  content: |
    To estimate AI costs:
    - Determine the number of words in the input prompt.
    - Calculate the cost based on the number of tokens, using the cost per 1000 tokens.
    - Calculate the cost of the output generated by the AI model.
    - Add the input and output costs to get the total estimated price.
    - For example, if an application calls the API 1000 times a day, calculate the daily and monthly costs based on the number of tokens used.

- title: What is the current pricing of AI models?
  content: |
    Pricing varies based on the model and is subject to change. Prices are per 1,000 tokens, with 1,000 tokens being about 750 words. Model-specific pricing is as follows:
    | Model                        | Input/Usage                  | Output/Usage                 |
    |------------------------------|------------------------------|------------------------------|
    | GPT-4 Turbo                  | $0.01 / 1K tokens            | $0.03 / 1K tokens            |
    | gpt-4-1106-vision-preview    | $0.01 / 1K tokens            | $0.03 / 1K tokens            |
    | GPT-4                        | $0.03 / 1K tokens            | $0.06 / 1K tokens            |
    | gpt-4-32k                    | $0.06 / 1K tokens            | $0.12 / 1K tokens            |
    | GPT-3.5-Turbo                | $0.0010 / 1K tokens          | $0.0020 / 1K tokens          |
    | gpt-3.5-turbo-instruct       | $0.0015 / 1K tokens          | $0.0020 / 1K tokens          |
    | Code Interpreter             | $0.03 / session              |                              |
    | DALL·E 3 Standard            | 1024×1024 - $0.040 / image   |                              |
    | DALL·E 3 HD                  | 1024×1024 - $0.080 / image   |                              |

